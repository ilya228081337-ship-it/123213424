# Приложение для транскрибации аудио с диаризацией

Веб-приложение для транскрибации аудиозаписей интервью с автоматическим распознаванием говорящих (диаризацией).

## Функциональность

- Загрузка аудиофайлов различных форматов
- Автоматическая транскрибация речи в текст
- Диаризация (разделение по говорящим: интервьюер/респондент)
- Временные метки для каждого сегмента разговора
- Интерактивный плеер с синхронизацией текста и аудио
- Хранение истории транскрипций

## Как использовать

1. **Регистрация/Вход**: Создайте аккаунт или войдите в существующий
2. **Загрузка аудио**: Перетащите аудиофайл в зону загрузки или выберите файл
   - Поддерживаются: MP3, WAV, M4A, OGG и другие форматы
3. **Транскрибация**: Нажмите "Начать транскрибацию" для обработки
   - Аудио будет воспроизводиться в фоновом режиме (очень тихо)
   - Web Speech API распознает речь в реальном времени
   - Происходит автоматическая диаризация с использованием ML-алгоритмов
4. **Просмотр результатов**: Результаты отобразятся с цветовой маркировкой говорящих:
   - Синий фон - интервьюер (обычно более низкий голос)
   - Зеленый фон - респондент (обычно более высокий голос)
5. **Навигация**: Кликайте на сегменты текста для перехода к соответствующему месту в аудио
6. **Экспорт**: Скачайте результаты в формате:
   - Текст (.txt) - читаемый формат с временными метками
   - SRT (.srt) - субтитры для видео
   - JSON (.json) - структурированные данные для дальнейшей обработки

## Технические детали

### Используемые технологии

- **Frontend**: React + TypeScript + Vite
- **UI**: TailwindCSS + Lucide React (иконки)
- **База данных**: Supabase (PostgreSQL)
- **Storage**: Supabase Storage для аудиофайлов
- **Транскрибация**: Web Speech API
- **Диаризация**: Анализ акустических характеристик (энергия, частота)

### Важные замечания

**Ограничения Web Speech API:**

1. **Поддержка браузеров**: Лучше всего работает в Chrome/Edge. Firefox и Safari имеют ограниченную поддержку
2. **Требуется интернет**: Web Speech API использует облачные сервисы Google
3. **Качество распознавания**: Зависит от качества аудио и четкости речи
4. **Язык**: Настроен на русский язык (ru-RU)
5. **Разрешения**: При первом запуске браузер может запросить доступ к микрофону - разрешите его

## Устранение проблем

### Ошибка "aborted"
- Это нормальное поведение при работе Web Speech API
- Приложение автоматически перезапускает распознавание
- Убедитесь, что у вас стабильное интернет-соединение

### Ошибка "not-allowed"
- Браузер заблокировал доступ к микрофону
- Решение: Откройте настройки сайта в браузере и разрешите доступ к микрофону
- В Chrome: кликните на иконку замка слева от адресной строки → Разрешения → Микрофон

### Ошибка "no-speech"
- Аудио не содержит распознаваемой речи или слишком тихое
- Проверьте, что файл действительно содержит речь
- Попробуйте другой аудиофайл с более четкой речью

### Низкое качество транскрипции
- Используйте аудиофайлы с четкой речью
- Избегайте файлов с фоновым шумом
- Оптимальный формат: MP3, битрейт 128 kbps или выше
- Записи в тихих помещениях дают лучшие результаты

**Диаризация:**

Текущая реализация использует продвинутые акустические характеристики и машинное обучение:
- K-means кластеризация для разделения на 2 говорящих
- Анализ энергии сигнала (громкость)
- Оценка высоты тона (pitch) - основной индикатор пола/возраста
- Zero-Crossing Rate (частота пересечения нуля) - характеристика тембра
- Сглаживание переходов между говорящими
- Автоматическое определение интервьюера по низкой средней высоте голоса

Для production-качества диаризации рекомендуется:
- Использовать специализированные ML-модели (pyannote.audio, ResNet-based speaker embeddings)
- Обучить модель на образцах голосов конкретных интервьюеров
- Использовать серверную обработку с большими моделями

### Структура базы данных

**speaker_profiles** - Библиотека голосов интервьюеров
- Хранит образцы голосов
- Voice embeddings для идентификации

**audio_recordings** - Загруженные аудиозаписи
- Метаданные файлов
- Статус обработки

**transcriptions** - Результаты транскрибации
- Текст сегментов
- Временные метки
- Привязка к говорящим

## Улучшения для production

Для получения качественной транскрибации с диаризацией рекомендуется:

1. **Использовать специализированные модели**:
   - Whisper от OpenAI для транскрибации
   - pyannote.audio для диаризации
   - Speaker verification модели для идентификации

2. **Серверная обработка**:
   - Обрабатывать аудио на сервере с GPU
   - Использовать Edge Functions или отдельный Python-бэкенд

3. **Обучение на данных**:
   - Собрать образцы голосов интервьюеров
   - Создать embeddings для каждого интервьюера
   - Использовать supervised learning для улучшения точности

4. **Пост-обработка**:
   - Коррекция ошибок транскрибации
   - Punctuation restoration
   - Speaker re-identification с использованием контекста

## Разработка

```bash
# Установка зависимостей
npm install

# Запуск dev-сервера
npm run dev

# Сборка
npm run build
```

## Безопасность

- Row Level Security (RLS) для всех таблиц
- Пользователи видят только свои данные
- Аудиофайлы хранятся с привязкой к пользователю
- Публичный доступ к аудио для воспроизведения через защищенные URL
